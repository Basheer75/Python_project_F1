# -*- coding: utf-8 -*-
"""F1 analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TKFGAmsjlmM6NoIdwA08cjS7smdwJiDI

#Overwiev
"""

# !pip install summarytools
# !pip install waterfallcharts

#library
import kagglehub
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import datetime as dt
import matplotlib.pyplot as plt
from summarytools import dfSummary
from IPython.display import display, HTML
import seaborn as sns
import waterfall_chart
import plotly.express as px
import random

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
rohanrao_formula_1_world_championship_1950_2020_path = kagglehub.dataset_download('rohanrao/formula-1-world-championship-1950-2020')

print('Data source import complete.')
print(rohanrao_formula_1_world_championship_1950_2020_path)

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load



# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory
for dirname, _, filenames in os.walk('C:/Users/DELL/OneDrive/Desktop/Anudip DAP/datasets'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

fpath='C:/Users/DELL/OneDrive/Desktop/Anudip DAP/datasets'

circuits = pd.read_csv(f'{fpath}/circuits.csv', index_col=0, na_values=r'\N')
constructorResults = pd.read_csv(f'{fpath}/cons_result.csv', index_col=0, na_values=r'\N')
constructors = pd.read_csv(f'{fpath}/constructors.csv', index_col=0, na_values=r'\N')
constructorStandings = pd.read_csv(f'{fpath}/cons_standing.csv', index_col=0, na_values=r'\N')
drivers = pd.read_csv(f'{fpath}/drivers.csv', index_col=0, na_values=r'\N')
driverStandings = pd.read_csv(f'{fpath}/driver_std.csv', index_col=0, na_values=r'\N')
lapTimes = pd.read_csv(f'{fpath}/lap_times.csv')
pitStops = pd.read_csv(f'{fpath}/pit_stop.csv')
qualifying = pd.read_csv(f'{fpath}/qualifying.csv', index_col=0, na_values=r'\N')
races = pd.read_csv(f'{fpath}/races.csv', na_values=r'\N')
results = pd.read_csv(f'{fpath}/results.csv', index_col=0, na_values=r'\N')
seasons = pd.read_csv(f'{fpath}/seasons.csv', index_col=0, na_values=r'\N')
status = pd.read_csv(f'{fpath}/status.csv', index_col=0, na_values=r'\N')

#---


# Data Cleaning and Preprocessing

circuits = circuits.rename(columns={'name':'circuitName','location':'circuitLocation','country':'circuitCountry','url':'circuitUrl'})
drivers = drivers.rename(columns={'nationality':'driverNationality','url':'driverUrl'})
drivers['driverName'] = drivers['forename']+' '+drivers['surname']
constructors = constructors.rename(columns={'name':'constructorName','nationality':'constructorNationality','url':'constructorUrl'})

# Fix for the ValueError:
races = races.reset_index() # Reset the index to include all columns
races = races[['raceId','year','round','circuitId','name','date','time','url']] # Select desired columns
races.set_index('raceId',inplace=True) # Set 'raceId' as the index
races['date'] = races['date'].apply(lambda x: dt.datetime.strptime(x,'%Y-%m-%d'))


pitStops = pitStops.rename(columns={'time':'pitTime'})
pitStops['seconds'] = pitStops['milliseconds'].apply(lambda x: x/1000)
results['seconds'] = results['milliseconds'].apply(lambda x: x/1000)

# copying all the data for workflow
circuits_ = circuits.copy()
constructorResults_ = constructorResults.copy()
constructors_ = constructors.copy()
constructorStandings_ = constructorStandings.copy()
drivers_ = drivers.copy()
driverStandings_ = driverStandings.copy()
lapTimes_ = lapTimes.copy()
pitStops_ = pitStops.copy()
qualifying_ = qualifying.copy()
races_ = races.copy()
results_ = results.copy()
seasons_ = seasons.copy()
status_ = status.copy()

def get_desired_summary(df):
    # Veri setinin genel bilgilerini düzenli bir şekilde göster
    display(HTML("<h2 style='color: #007bff;'>Dataset Info</h2>"))
    display(HTML(f"<h4 style='color: #6c757d;'>Shape: {df.shape}</h4>"))
    display(HTML(f"<h4 style='color: #6c757d;'>Number of Columns: {df.shape[1]}</h4>"))
    display(HTML(f"<h4 style='color: #6c757d;'>Number of Rows: {df.shape[0]}</h4>"))
    display(HTML("<hr>"))

    # Info fonksiyonunu daha belirgin hale getirmek için
    display(HTML("<h2 style='color: #28a745;'>Dataset Info Summary</h2>"))
    display(HTML("<h4 style='color: #6c757d;'>Column types and missing data</h4>"))
    display(df.info())
    display(HTML("<hr>"))

    # DataFrame Summary'yi görselleştirme
    display(HTML("<h2 style='color: #17a2b8;'>Dataset Summary</h2>"))
    return dfSummary(df)

# Kullanım örneği
get_desired_summary(pitStops_)

import plotly.express as px
import pandas as pd

# Merged DataFrame (already created in your code)
merged_df = drivers_.merge(driverStandings_, on='driverId').drop_duplicates()

# Add 'wins' and 'points' aggregation
top_10_winners = (
    merged_df[merged_df['position'] == 1].groupby(['driverName', 'driverUrl'])['wins']
    .count()
    .nlargest(10)
    .reset_index()
)

top_10_points = (
    merged_df.groupby(['driverName', 'driverUrl'])['points']
    .sum()
    .nlargest(10)
    .reset_index()
)

# Top 10 Winners Chart with Clickable Links
fig_winners = px.bar(
    top_10_winners,
    x='wins',
    y='driverName',
    orientation='h',  # Horizontal bar for better readability
    title='Top 10 Drivers by Wins',
    labels={'driverName': 'Driver', 'wins': 'Wins'},
    custom_data=['driverUrl'],  # Pass the link data for interactivity
)

# Customize hover to show the link
fig_winners.update_traces(
    hovertemplate="<b>%{y}</b><br>Wins: %{x}<br><a href='%{customdata[0]}'>Driver Profile</a>"
)

# Open URL on click
fig_winners.update_layout(clickmode='event+select')
fig_winners.show()

# Top 10 Points Chart with Clickable Links
fig_points = px.bar(
    top_10_points,
    x='points',
    y='driverName',
    orientation='h',  # Horizontal bar for better readability
    title='Top 10 Drivers by Points',
    labels={'driverName': 'Driver', 'points': 'Points'},
    custom_data=['driverUrl'],  # Pass the link data for interactivity
)

# Customize hover to show the link
fig_points.update_traces(
    hovertemplate="<b>%{y}</b><br>Points: %{x}<br><a href='%{customdata[0]}'>Driver Profile</a>"
)

# Open URL on click
fig_points.update_layout(clickmode='event+select')
fig_points.show()

# Calculate average qualifying position for each driver
qualifying_analysis = (
    merged_df.groupby('driverName')['position']
    .mean()
    .sort_values()
    .head(10)
    .reset_index()
)
fig_qual = px.bar(
    qualifying_analysis,
    x='driverName',
    y='position',
    title="Average Qualifying Position for Top Drivers",
    labels={'driverName': 'Driver', 'position': 'Average Position'}
)
fig_qual.show()

merged_df.tail()

# Check for duplicates
merged_df.duplicated()

# Example: Count races where they finished first
dominance = merged_df[(merged_df['position'] == 1)].drop_duplicates().groupby('driverName')['raceId'].count().reset_index()

fig_dominance = px.scatter(
    dominance,
    x='driverName',
    y='raceId',
    title="Number of Races Dominated (Wins)",
    labels={"driverName": "Driver", "raceId": "Number of Wins"},
    hover_name="driverName",
    hover_data={"raceId": True},
    color="raceId",
    color_continuous_scale="Viridis",
    template="plotly_dark"
)


fig_dominance.show()

# Filter seasons with close points between top drivers
races_.head()

merged_df.info()

"""## optimization"""

# Convert relevant columns to categorical type
merged_df['driverRef'] = merged_df['driverRef'].astype('category')
merged_df['code'] = merged_df['code'].astype('category')
merged_df['driverNationality'] = merged_df['driverNationality'].astype('category')
merged_df['driverUrl'] = merged_df['driverUrl'].astype('category')
merged_df['driverName'] = merged_df['driverName'].astype('category')
merged_df['positionText'] = merged_df['positionText'].astype('category')

# Check the changes
print(merged_df.info())
display(merged_df.head(20))

"""`we made optimization to reach numerical data and other type as u can see`"""

# prompt: select only numerical datas from merged df

# Select only numerical columns
driver_numerical_rank_df = merged_df.select_dtypes(include=np.number)
driver_categorical_data = merged_df[['driverId','driverRef','driverNationality','driverUrl','driverName','positionText']]
# Display the numerical DataFrame
display(driver_numerical_rank_df.head(20).info(),driver_categorical_data.head(20).info())

import pandas as pd

# First merge 'constructors_' with 'constructorResults_'
constructors_merged_df = pd.merge(constructors_, constructorResults_, on='constructorId')

# Then merge the result with 'constructorStandings_'
constructors_merged_df = pd.merge(constructors_merged_df, constructorStandings_, on='constructorId')

constructors_merged_df.drop(columns=['status','points_x','constructorUrl','constructorRef','raceId_x'],inplace=True)
constructors_merged_df.rename(columns={'points_y':'points','raceId_y':'raceId'},inplace=True)
constructors_merged_df.sort_values(by='wins',ascending=False).head()

"""## constructors_ memory optimizization"""

constructors_merged_df['constructorName']=constructors_merged_df['constructorName'].astype('category')
constructors_merged_df['constructorNationality']=constructors_merged_df['constructorNationality'].astype('category')
constructors_merged_df['positionText']=constructors_merged_df['positionText'].astype('category')
# Downcast numeric columns to save memory
constructors_merged_df['raceId'] = pd.to_numeric(constructors_merged_df['raceId'], downcast='integer')
constructors_merged_df['points'] = pd.to_numeric(constructors_merged_df['points'], downcast='float')
constructors_merged_df['position'] = pd.to_numeric(constructors_merged_df['position'], downcast='integer')
constructors_merged_df['wins'] = pd.to_numeric(constructors_merged_df['wins'], downcast='integer')

constructors_merged_df.info()

"""showcase the constructors_ best"""

# Group by constructor and sum points
top_constructors = constructors_merged_df.drop_duplicates().groupby('constructorName')['points'].agg(np.sum).nlargest(10).reset_index()

# Create the bar chart
fig_constructors = px.bar(
    top_constructors,
    x='constructorName',
    y='points',
    title='Top 10 Constructors by Total Points',
    labels={'constructorName': 'Constructor', 'points': 'Total Points'}
)
fig_constructors.update_layout(
    xaxis_title="Constructor",
    yaxis_title="Total Points",
    xaxis_tickangle=45,  # Tilt x-axis labels for better readability
    template="plotly_dark"  # Dark theme
)


fig_constructors.show()

# Filter data for rows where the position is 1 (i.e., finished in 1st place)
top_10_winners = constructors_merged_df[constructors_merged_df['position'] == 1].drop_duplicates()
# Group by 'constructorName' and sum the 'wins' for each constructor
top_10_winners = top_10_winners.groupby('constructorName')['wins'].count().nlargest(10).reset_index()

# Visualize the results in a bar chart
import plotly.express as px

fig = px.bar(
    top_10_winners,
    x='constructorName',
    y='wins',
    title='Top 10 Constructors by Wins in First Position',
    labels={'constructorName': 'Constructor', 'wins': 'Wins'},
    color='wins',  # Color by number of wins
    text='wins'    # Show win count on the bars
)

# Customize the layout for better readability
fig.update_layout(
    xaxis_title="Constructor",
    yaxis_title="Total Wins",
    xaxis_tickangle=45,  # Tilt x-axis labels for readability
    template="plotly_dark"  # Optional: dark theme for the plot
)

# Show the chart
fig.show()

display(constructors_merged_df.head().info(),merged_df.head().info())

# Merge the necessary DataFrames
driver_constructor_df = pd.merge(merged_df.drop_duplicates(), constructors_merged_df.drop_duplicates(), on='raceId', suffixes=('_driver', '_constructor'))

# Create a new DataFrame with driver and constructor information

# Display the DataFrame
driver_constructor_df.info()

# Filter for wins
wins_df = driver_constructor_df[driver_constructor_df['position_driver'] == 1].drop_duplicates()

# Group by driver and constructor, count wins
win_counts = wins_df.groupby(['driverName', 'constructorName'])['raceId'].count().reset_index()

# Rename columns for clarity
win_counts.rename(columns={'raceId': 'win_count'}, inplace=True)

# Sort by win counts to see the most successful driver-constructor pairs
win_counts = win_counts.sort_values(by='win_count', ascending=False)

win_counts.drop_duplicates()

fig = px.scatter(
    win_counts[win_counts['win_count']>0],
    x='driverName',
    y='win_count',
    color='constructorName',
    title='Number of Wins by Driver and Constructor',
    labels={'driverName': 'Driver', 'win_count': 'Number of Wins', 'constructorName': 'Constructor'},
    hover_data=['constructorName', 'win_count'],
    template="plotly_dark"
)

fig.update_layout(
    xaxis_title="Driver",
    yaxis_title="Number of Wins",
    xaxis_tickangle=45,  # Rotate x-axis labels for better readability
)

fig.show()

get_desired_summary(driver_constructor_df)

"""#pitstop comparetion

# race places
"""

# Merge data
merged_df = (
    pitStops_
    .merge(results, on=["raceId", "driverId"], how="inner")
    .merge(constructors_, on="constructorId", how="inner")
)

# Filter for valid pit stops
merged_df = merged_df[merged_df["milliseconds_x"].notnull() & (merged_df["milliseconds_x"] > 0)].drop_duplicates()

# Convert milliseconds to seconds
merged_df["pit_stop_time"] = merged_df["milliseconds_x"] / 1000

# Calculate average pit stop time, standard deviation, and count by constructor
avg_pit_stop = (
    merged_df.groupby("constructorName")["pit_stop_time"]
    .agg(["mean", "std", "count"])
    .reset_index()
)
avg_pit_stop.rename(columns={"mean": "avg_pit_stop_time", "std": "std_dev", "count": "pit_stop_count"}, inplace=True)

# Analyze race performance: Wins by constructor
race_performance = (
    merged_df[merged_df["position"] == 1]  # Wins only
    .groupby("constructorName")["raceId"]
    .count()
    .reset_index()
)
race_performance.rename(columns={"raceId": "win_count"}, inplace=True)

# Merge performance data with pit stop analysis
performance_df = avg_pit_stop.merge(race_performance, on="constructorName", how="left")
performance_df["win_count"] = performance_df["win_count"].fillna(0)

# Visualize average pit stop time by constructor
fig_bar = px.bar(
    performance_df.sort_values("avg_pit_stop_time"),
    x="constructorName",
    y="avg_pit_stop_time",
    error_y="std_dev",
    title="Average Pit Stop Time by Constructor",
    labels={"constructorName": "Constructor", "avg_pit_stop_time": "Average Pit Stop Time (s)"},
    color="pit_stop_count",  # Add color scale for pit stop count
    text="pit_stop_count"    # Show pit stop count as text on bars
)
fig_bar.update_layout(
    xaxis_tickangle=45,
    template="plotly_white"
)
fig_bar.show()

# Visualize correlation between average pit stop time and wins
fig_scatter = px.scatter(
    performance_df,
    x="avg_pit_stop_time",
    y="win_count",
    size="pit_stop_count",
    color="constructorName",
    title="Correlation Between Pit Stop Time and Wins",
    labels={"avg_pit_stop_time": "Average Pit Stop Time (s)", "win_count": "Number of Wins"},
    hover_name="constructorName"
)
fig_scatter.update_traces(marker=dict(opacity=0.8, line=dict(width=1)))
fig_scatter.update_layout(template="plotly_white")
fig_scatter.show()

# Heatmap for correlation
correlation_matrix = performance_df[["avg_pit_stop_time", "std_dev", "win_count"]].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", cbar=True)
plt.title("Correlation Between Pit Stop Time and Wins")
plt.show()

"""#missing value creating and fetching to our data

"""

get_desired_summary(merged_df.drop_duplicates())

def add_random_missing_values(dataframe: pd.DataFrame,
                              missing_rate: float = 0.05) -> pd.DataFrame:
    """Turns random values to NaN in a DataFrame.

    To use this function, you need to import pandas, numpy and random libraries.

    Args:
        dataframe (pd.DataFrame): DataFrame to be processed.
        missing_rate (float): Percentage of missing value rate in float format. Defaults 0.05

    Returns:
        df_missing (pd.DataFrame): Processed DataFrame object.

    """
    # Get copy of dataframe
    df_missing = dataframe.copy()

    # Obtain size of dataframe and number total number of missing values
    df_size = dataframe.size
    num_missing = int(df_size * missing_rate)

    # Get random row and column indexes to turn them NaN
    for _ in range(num_missing):
        row_idx = random.randint(0, dataframe.shape[0] - 1)
        col_idx = random.randint(0, dataframe.shape[1] - 1)

        df_missing.iat[row_idx, col_idx] = np.nan

    return df_missing

merged_df_numerical=merged_df.select_dtypes(include=np.number)
merged_df_categorical=merged_df.select_dtypes(exclude=np.number)
pd.set_option('display.max_columns', None)
merged_df_numerical=merged_df_numerical.iloc[:,:-3].sort_values(by='constructorId',ascending=True)

display(merged_df_numerical.head(),merged_df_numerical.isnull().sum())
sns.heatmap(merged_df_numerical.isnull(),cbar=False)

merged_df_numerical

sns.heatmap(merged_df_numerical.corr(),cbar=True)

import pandas as pd
import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.ensemble import RandomForestRegressor




# Iterative Imputer ile eksik değerleri doldurun
imputer = IterativeImputer(estimator=RandomForestRegressor(), random_state=42, max_iter=10)
imputed_data = imputer.fit_transform(merged_df_numerical[merged_df_numerical.isnull().any(axis=1)]
)

# Doldurulmuş veriyi tekrar DataFrame formatına çevirin
df_imputed = pd.DataFrame(imputed_data, columns=merged_df_numerical.columns)

# Sonucu görüntüleyin
print("Eksik değerler doldurulduktan sonra veri:")
print(df_imputed)

# Eksik değer kontrolü
print("\nVeri setinde kalan eksik değer sayısı:")
print(df_imputed.isnull().sum())

df_imputed=df_imputed.convert_dtypes()
df_imputed.info()

cleared_cat_=merged_df_categorical.dropna()
cleared_cat_.info()

merged_df_new=pd.concat([df_imputed,cleared_cat_],axis=1)
merged_df_new.info()

"""`read for ml data
`
"""

merged_df_new

"""## extras"""

# Scatter map with Plotly Express
fig = px.scatter_mapbox(
    circuits_,
    lat="lat",               # Latitude column
    lon="lng",               # Longitude column
    hover_name="circuitName",  # Correct column for circuit names
    hover_data={"circuitLocation": True,  # Add extra hover information
                "circuitCountry": True,
                "alt": True,
                "circuitUrl": False},  # Hide URL from the hover fields, we'll format it separately
    title="F1 Circuits Around the World",
    zoom=1,                  # Initial zoom level
    height=600
)

# Change the map style
fig.update_layout(mapbox_style="carto-positron")

# Customize hovertemplate for clickable links
fig.update_traces(
    hovertemplate=(
        "<b>%{hovertext}</b><br>"  # Circuit name
        "Location: %{customdata[0]}, %{customdata[1]}<br>"  # Location and Country
        "Altitude: %{customdata[2]}<br>"  # Altitude
        "<a href='%{customdata[3]}' target='_blank'>Circuit Link</a>"  # Add clickable link
    ),
    customdata=circuits_[["circuitLocation", "circuitCountry", "alt", "circuitUrl"]].values  # Pass extra hover data
)

# Show the map
fig.show()